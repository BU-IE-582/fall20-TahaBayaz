{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELECTRICITY CONSUMPTION FORECAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data\n",
    "\n",
    "The data that we collected is about the electricity consumption from 1st of January, 2016 till the 1st of December, 2020. The data have data, hour and electricity consumption(MWh) as variables. This data can be reached from this [link](https://seffaflik.epias.com.tr/transparency/tuketim/gerceklesen-tuketim/gercek-zamanli-tuketim.xhtml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Objective\n",
    "\n",
    "In this assignment, we want to forecast the electirict consumptions of the next day's consumptions. In all tasks, we will use the data from 1st of November, 2020 till the end as test data. In this assignment, our performance metric will be mean absolute percentage error (MAPE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TASKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Packages and Funcitons\n",
    "\n",
    "Throughout the assignment, we will use __numpy__, __pandas__, __datatable__, __matplotlib.pyplot__ and __CVXPY__ packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Importing Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datatable as dt\n",
    "from datatable import f, shift, update, join, by, mean, isna\n",
    "from datatable.math import abs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "import statsmodels.api as sm\n",
    "import cvxpy as cp\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('error')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are calculating the MAPE, we will use _calculate_mape_ function. When we want to get the long or wide format of the data, we will use _transform_long_ and _transform_wide_ functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mape(dt):\n",
    "    temp = dt\n",
    "    temp[:, update(MAPE = mean(abs((f.pred - f.true) / f.true)) * 100)]\n",
    "    return temp[0, \"MAPE\"]\n",
    "\n",
    "def transform_long(df):\n",
    "    long = df.copy()\n",
    "    long[:,update(Lag_48 = shift(f[\"Consumption\"], n = 48), Lag_168 = shift(f[\"Consumption\"], n = 168))]\n",
    "    # We can remove 7 days from data, because 7 << 1797.\n",
    "    return long[169:long.nrows, [\"Date\", \"Hour\", \"Lag_48\", \"Lag_168\", \"Consumption\"]]\n",
    "\n",
    "def transform_wide(df):\n",
    "    df2 = df.to_pandas()\n",
    "    lag_48 = pd.pivot_table(df2, index = 'Date', columns = 'Hour', values = 'Lag_48', aggfunc=np.mean, fill_value=0).reset_index()\n",
    "    lag_168 = pd.pivot_table(df2, index = 'Date', columns = 'Hour', values = 'Lag_168', aggfunc=np.mean, fill_value=0).reset_index()\n",
    "    df2[\"Date\"] = df2[\"Date\"].astype(str)\n",
    "    lag_48[\"Date\"] = lag_48[\"Date\"].astype(str)\n",
    "    lag_168[\"Date\"] = lag_168[\"Date\"].astype(str)\n",
    "    df2 = dt.Frame(df2)\n",
    "    lag_48 = dt.Frame(lag_48)\n",
    "    lag_168 = dt.Frame(lag_168)\n",
    "    lag_48.names = ['Date'] + [\"Lag_day2_hour\" + str(i) for i in range(0, 24)]\n",
    "    lag_168.names = ['Date'] + [\"Lag_day7_hour\" + str(i) for i in range(0, 24)]\n",
    "    lag_48.key = 'Date'\n",
    "    lag_168.key = 'Date'\n",
    "    temp = df2[:, :, join(lag_48)]\n",
    "    wide = temp[:, :, join(lag_168)]\n",
    "    wide = wide[:, f[:].remove([f.Lag_48, f.Lag_168])]\n",
    "    return wide[:, [0, 1, range(3, 51), 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Manupilation\n",
    "\n",
    "Before starting tasks, we need to import the data and change the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>Date</th><th>Hour</th><th>Consumption</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>01.01.2016</td><td>00:00</td><td>26.277,24</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>01.01.2016</td><td>01:00</td><td>24.991,82</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>01.01.2016</td><td>02:00</td><td>23.532,61</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>01.01.2016</td><td>03:00</td><td>22.464,78</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>01.01.2016</td><td>04:00</td><td>22.002,91</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>01.01.2016</td><td>05:00</td><td>21.957,08</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>01.01.2016</td><td>06:00</td><td>22.203,54</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>01.01.2016</td><td>07:00</td><td>21.844,16</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>01.01.2016</td><td>08:00</td><td>23.094,73</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>01.01.2016</td><td>09:00</td><td>25.202,27</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>10 rows &times; 3 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#142041bf2d0 10x3>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity = dt.fread(\"GercekZamanliTuketim.csv\", columns = ['Date', 'Hour', 'Consumption'])\n",
    "electricity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `Date` column is character type column. So need to change the type of the variable and check that do we have information for all days from 1st of January, 2016 till the 1st of December, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DateTime = electricity[:, f.Date + \" \" + f.Hour]\n",
    "DateTime = DateTime.to_pandas()\n",
    "DateTime = DateTime.apply(pd.to_datetime, format = \"%d.%m.%Y %H:%M\")\n",
    "\n",
    "electricity[:, update(DateTime = DateTime.values)]\n",
    "electricity[:, update(Date = DateTime.iloc[:,0].dt.date)]\n",
    "electricity[:, update(Hour = DateTime.iloc[:,0].dt.hour)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>Date</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='object' title='obj64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>2016-01-01</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>2016-01-02</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>2016-01-03</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>2016-01-04</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>2016-01-05</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>2016-01-06</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>2016-01-07</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>2016-01-08</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>2016-01-09</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>2016-01-10</td></tr>\n",
       "    <tr><td class='row_index'>10</td><td>2016-01-11</td></tr>\n",
       "    <tr><td class='row_index'>11</td><td>2016-01-12</td></tr>\n",
       "    <tr><td class='row_index'>12</td><td>2016-01-13</td></tr>\n",
       "    <tr><td class='row_index'>13</td><td>2016-01-14</td></tr>\n",
       "    <tr><td class='row_index'>14</td><td>2016-01-15</td></tr>\n",
       "    <tr><td class='row_index'>&#x22EE;</td><td class='hellipsis'>&#x22EE;</td></tr>\n",
       "    <tr><td class='row_index'>1792</td><td>2020-11-27</td></tr>\n",
       "    <tr><td class='row_index'>1793</td><td>2020-11-28</td></tr>\n",
       "    <tr><td class='row_index'>1794</td><td>2020-11-29</td></tr>\n",
       "    <tr><td class='row_index'>1795</td><td>2020-11-30</td></tr>\n",
       "    <tr><td class='row_index'>1796</td><td>2020-12-01</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>1797 rows &times; 1 column</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#14204187120 1797x1>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = dt.Frame(Date = np.unique(electricity[\"Date\"]))\n",
    "days[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1796\n"
     ]
    }
   ],
   "source": [
    "lag_1_day = shift(days, n = 1)\n",
    "print(sum([lag_1_day[i+1,0] == days[i,0] for i in range(0, days.nrows - 1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result, we can say that we have electricity consumption information for all days. Now, we need to check whether we have electricity consumption information for all hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Hour\n",
      "-- + ----\n",
      " 0 |    0\n",
      " 1 |    1\n",
      " 2 |    2\n",
      " 3 |    3\n",
      " 4 |    4\n",
      " 5 |    5\n",
      " 6 |    6\n",
      " 7 |    7\n",
      " 8 |    8\n",
      " 9 |    9\n",
      "10 |   10\n",
      "11 |   11\n",
      "12 |   12\n",
      "13 |   13\n",
      "14 |   14\n",
      "15 |   15\n",
      "16 |   16\n",
      "17 |   17\n",
      "18 |   18\n",
      "19 |   19\n",
      "20 |   20\n",
      "21 |   21\n",
      "22 |   22\n",
      "23 |   23\n",
      "\n",
      "[24 rows x 1 column]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hours = dt.Frame(Hour = np.unique(electricity[:,'Hour']))\n",
    "print(hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "lag_1_hour = shift(hours, n = 1)\n",
    "print(sum([lag_1_hour[i+1,0] == hours[i,0] for i in range(0, hours.nrows - 1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result, we can say that we have electricity consumption information for all days. Now, we need to check whether we have electricity consumption information for all hours of all days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-30    24\n",
      "2019-11-14    24\n",
      "2018-04-24    24\n",
      "2017-11-23    24\n",
      "2018-11-20    24\n",
      "Name: Date, dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "Date = electricity[\"Date\"].to_pandas()\n",
    "print(Date[\"Date\"].value_counts().head())\n",
    "print(sum(Date[\"Date\"].value_counts() != 24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for all days we have 24 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4     1798\n",
      "23    1797\n",
      "22    1797\n",
      "1     1797\n",
      "2     1797\n",
      "5     1797\n",
      "6     1797\n",
      "7     1797\n",
      "8     1797\n",
      "9     1797\n",
      "10    1797\n",
      "11    1797\n",
      "12    1797\n",
      "13    1797\n",
      "14    1797\n",
      "15    1797\n",
      "16    1797\n",
      "17    1797\n",
      "18    1797\n",
      "19    1797\n",
      "20    1797\n",
      "21    1797\n",
      "0     1797\n",
      "3     1796\n",
      "Name: Hour, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Hour = electricity[\"Hour\"].to_pandas()\n",
    "print(Hour[\"Hour\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the table, there is a missing row for hour 3 and there is an addition for hour 4. As we have checked in the chunk before the previous one, we know that there 24 hours for all days. So, these errors are in the same date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>2016-03-27T04:00:00.000000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           DateTime  count\n",
       "2067  2016-03-27T04:00:00.000000000      2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = electricity[:,dt.count(), by([\"DateTime\"])].to_pandas()\n",
    "temp[temp.iloc[:,1].isin([2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the problem is in the _2016-03-27_ date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>Date</th><th>Hour</th><th>Consumption</th><th>DateTime</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='object' title='obj64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>2016-03-27</td><td>0</td><td>27.424,42</td><td>2016-03-27T00:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>2016-03-27</td><td>1</td><td>25.949,63</td><td>2016-03-27T01:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>2016-03-27</td><td>2</td><td>0,00</td><td>2016-03-27T02:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>2016-03-27</td><td>4</td><td>24.776,94</td><td>2016-03-27T04:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>2016-03-27</td><td>4</td><td>24.776,94</td><td>2016-03-27T04:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>2016-03-27</td><td>5</td><td>24.098,97</td><td>2016-03-27T05:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>2016-03-27</td><td>6</td><td>23.267,43</td><td>2016-03-27T06:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>2016-03-27</td><td>7</td><td>22.531,83</td><td>2016-03-27T07:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>2016-03-27</td><td>8</td><td>23.398,59</td><td>2016-03-27T08:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>2016-03-27</td><td>9</td><td>24.969,23</td><td>2016-03-27T09:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>10</td><td>2016-03-27</td><td>10</td><td>26.791,03</td><td>2016-03-27T10:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>11</td><td>2016-03-27</td><td>11</td><td>27.831,89</td><td>2016-03-27T11:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>12</td><td>2016-03-27</td><td>12</td><td>28.103,55</td><td>2016-03-27T12:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>13</td><td>2016-03-27</td><td>13</td><td>28.415,16</td><td>2016-03-27T13:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>14</td><td>2016-03-27</td><td>14</td><td>28.198,17</td><td>2016-03-27T14:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>15</td><td>2016-03-27</td><td>15</td><td>27.818,62</td><td>2016-03-27T15:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>16</td><td>2016-03-27</td><td>16</td><td>27.725,57</td><td>2016-03-27T16:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>17</td><td>2016-03-27</td><td>17</td><td>27.889,38</td><td>2016-03-27T17:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>18</td><td>2016-03-27</td><td>18</td><td>28.717,76</td><td>2016-03-27T18:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>19</td><td>2016-03-27</td><td>19</td><td>30.886,46</td><td>2016-03-27T19:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>20</td><td>2016-03-27</td><td>20</td><td>31.451,53</td><td>2016-03-27T20:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>21</td><td>2016-03-27</td><td>21</td><td>30.768,18</td><td>2016-03-27T21:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>22</td><td>2016-03-27</td><td>22</td><td>30.826,26</td><td>2016-03-27T22:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>23</td><td>2016-03-27</td><td>23</td><td>29.299,73</td><td>2016-03-27T23:00:00.000000000</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>24 rows &times; 4 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#14209f281e0 24x4>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity[electricity[\"Date\"].to_pandas()[\"Date\"].astype(str).str.contains(\"2016-03-27\"), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the table above, we have some problem for this day. The error is due to the the daylight savings program Turkey used to apply in those years. To correct the error, we will change the hour from 4 to 3 and replace the `Consumption` column with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>Date</th><th>Hour</th><th>Consumption</th><th>DateTime</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='object' title='obj64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>2016-03-27</td><td>0</td><td>27.424,42</td><td>2016-03-27T00:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>2016-03-27</td><td>1</td><td>25.949,63</td><td>2016-03-27T01:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>2016-03-27</td><td>2</td><td>0,00</td><td>2016-03-27T02:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>2016-03-27</td><td>3</td><td>0,00</td><td>2016-03-27T04:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>2016-03-27</td><td>4</td><td>24.776,94</td><td>2016-03-27T04:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>2016-03-27</td><td>5</td><td>24.098,97</td><td>2016-03-27T05:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>2016-03-27</td><td>6</td><td>23.267,43</td><td>2016-03-27T06:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>2016-03-27</td><td>7</td><td>22.531,83</td><td>2016-03-27T07:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>2016-03-27</td><td>8</td><td>23.398,59</td><td>2016-03-27T08:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>2016-03-27</td><td>9</td><td>24.969,23</td><td>2016-03-27T09:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>10</td><td>2016-03-27</td><td>10</td><td>26.791,03</td><td>2016-03-27T10:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>11</td><td>2016-03-27</td><td>11</td><td>27.831,89</td><td>2016-03-27T11:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>12</td><td>2016-03-27</td><td>12</td><td>28.103,55</td><td>2016-03-27T12:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>13</td><td>2016-03-27</td><td>13</td><td>28.415,16</td><td>2016-03-27T13:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>14</td><td>2016-03-27</td><td>14</td><td>28.198,17</td><td>2016-03-27T14:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>15</td><td>2016-03-27</td><td>15</td><td>27.818,62</td><td>2016-03-27T15:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>16</td><td>2016-03-27</td><td>16</td><td>27.725,57</td><td>2016-03-27T16:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>17</td><td>2016-03-27</td><td>17</td><td>27.889,38</td><td>2016-03-27T17:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>18</td><td>2016-03-27</td><td>18</td><td>28.717,76</td><td>2016-03-27T18:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>19</td><td>2016-03-27</td><td>19</td><td>30.886,46</td><td>2016-03-27T19:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>20</td><td>2016-03-27</td><td>20</td><td>31.451,53</td><td>2016-03-27T20:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>21</td><td>2016-03-27</td><td>21</td><td>30.768,18</td><td>2016-03-27T21:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>22</td><td>2016-03-27</td><td>22</td><td>30.826,26</td><td>2016-03-27T22:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>23</td><td>2016-03-27</td><td>23</td><td>29.299,73</td><td>2016-03-27T23:00:00.000000000</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>24 rows &times; 4 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#14209f0aa50 24x4>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where(electricity[\"Date\"].to_pandas()[\"Date\"].astype(str).str.contains(\"2016-03-27\"))[0]\n",
    "datetime = \"2016-03-27 03:00\"\n",
    "electricity[int(idx[3]), \"Hour\"] = 3\n",
    "electricity[int(idx[3]), \"Consumption\"] = \"0,00\"\n",
    "\n",
    "electricity[electricity[\"Date\"].to_pandas()[\"Date\"].astype(str).str.contains(\"2016-03-27\"), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we finished the control related with any DateTime information. We need to check the type of the consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(electricity[0,\"Consumption\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should a numeric variable. So, we need to convert it to character. But, as we saw from the `electricity.head()` command, comma is used as decimal separator and period is used as a thousand separator. So, we can use `replace` function to solve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Consumption = electricity[:, f.Consumption].to_pandas()\n",
    "electricity[\"Consumption\"] = Consumption[\"Consumption\"].str.replace(\".\", \"\").str.replace(\",\", \".\").astype(float).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check `Consumption` values whether there are 0 or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>Date</th><th>Hour</th><th>Consumption</th><th>DateTime</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='object' title='obj64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>2016-03-27</td><td>2</td><td>0</td><td>2016-03-27T02:00:00.000000000</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>2016-03-27</td><td>3</td><td>0</td><td>2016-03-27T04:00:00.000000000</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>2 rows &times; 4 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#1420a079870 2x4>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity[f.Consumption == 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are two zero values in `Consumption` column. We can assign the average consumption of that hour for zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>Date</th><th>Hour</th><th>Consumption</th><th>DateTime</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='object' title='obj64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>0 rows &times; 4 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#14209f28600 0x4>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity[f.Consumption == 0, update(Consumption = np.NaN)]\n",
    "mean_2 = electricity[f.Hour == 2, mean(f.Consumption)]\n",
    "mean_3 = electricity[f.Hour == 3, mean(f.Consumption)]\n",
    "\n",
    "electricity[(isna(f.Consumption)) & (f.Hour == 2), update(Consumption = mean_2)]\n",
    "electricity[(isna(f.Consumption)) & (f.Hour == 3), update(Consumption = mean_3)]\n",
    "electricity[isna(f.Consumption),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we solved all problems in the data. To easily identify the train and test data, we can create a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Date  Hour  Consumption  DateTime                       Test\n",
      "-- + ----  ----  -----------  -----------------------------  ----\n",
      " 0 |          0      26277.2  2016-01-01T00:00:00.000000000     0\n",
      " 1 |          1      24991.8  2016-01-01T01:00:00.000000000     0\n",
      " 2 |          2      23532.6  2016-01-01T02:00:00.000000000     0\n",
      " 3 |          3      22464.8  2016-01-01T03:00:00.000000000     0\n",
      " 4 |          4      22002.9  2016-01-01T04:00:00.000000000     0\n",
      " 5 |          5      21957.1  2016-01-01T05:00:00.000000000     0\n",
      " 6 |          6      22203.5  2016-01-01T06:00:00.000000000     0\n",
      " 7 |          7      21844.2  2016-01-01T07:00:00.000000000     0\n",
      " 8 |          8      23094.7  2016-01-01T08:00:00.000000000     0\n",
      " 9 |          9      25202.3  2016-01-01T09:00:00.000000000     0\n",
      "\n",
      "[10 rows x 5 columns]\n",
      "\n",
      "   | Date  Hour  Consumption  DateTime                       Test\n",
      "-- + ----  ----  -----------  -----------------------------  ----\n",
      " 0 |         14      41812.3  2020-12-01T14:00:00.000000000     1\n",
      " 1 |         15      41722.8  2020-12-01T15:00:00.000000000     1\n",
      " 2 |         16      42341.2  2020-12-01T16:00:00.000000000     1\n",
      " 3 |         17      43320.3  2020-12-01T17:00:00.000000000     1\n",
      " 4 |         18      42292.1  2020-12-01T18:00:00.000000000     1\n",
      " 5 |         19      40720.2  2020-12-01T19:00:00.000000000     1\n",
      " 6 |         20      39195.7  2020-12-01T20:00:00.000000000     1\n",
      " 7 |         21      38310.8  2020-12-01T21:00:00.000000000     1\n",
      " 8 |         22      37174    2020-12-01T22:00:00.000000000     1\n",
      " 9 |         23      35725.5  2020-12-01T23:00:00.000000000     1\n",
      "\n",
      "[10 rows x 5 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx2 = np.min(np.where(electricity[\"Date\"].to_pandas()[\"Date\"].astype(str).str.contains(\"2020-11-01\"))[0])\n",
    "electricity[:, update(Test = 0)]\n",
    "electricity[int(idx2):, update(Test = 1)]\n",
    "print(electricity.head())\n",
    "print(electricity.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reached final shape of the data. Throughout the assignment, we will use some formats of this data, which are in long and wide format. We can get these formatted data from the code below. Also, we removed first 186 rows from `electricity` data, because we removed the rows with NAs in `electricity_long` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Date  Hour   Lag_48  Lag_168  Consumption\n",
      "-- + ----  ----  -------  -------  -----------\n",
      " 0 |          1  27614    24991.8      27112.4\n",
      " 1 |          2  26579    23532.6      25975.3\n",
      " 2 |          3  25719.2  22464.8      25315.5\n",
      " 3 |          4  25864.6  22002.9      25128.2\n",
      " 4 |          5  25918.6  21957.1      25356.2\n",
      " 5 |          6  27091.9  22203.5      26338.7\n",
      " 6 |          7  28533    21844.2      28086.4\n",
      " 7 |          8  33203.3  23094.7      32702.2\n",
      " 8 |          9  36257.2  25202.3      35788.2\n",
      " 9 |         10  37212.9  27225        36843.2\n",
      "\n",
      "[10 rows x 5 columns]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>Date</th><th>Hour</th><th>Lag_day2_hour0</th><th>Lag_day2_hour1</th><th>Lag_day2_hour2</th><th>Lag_day2_hour3</th><th>Lag_day2_hour4</th><th>Lag_day2_hour5</th><th>Lag_day2_hour6</th><th>Lag_day2_hour7</th><th class='vellipsis'>&hellip;</th><th>Lag_day7_hour20</th><th>Lag_day7_hour21</th><th>Lag_day7_hour22</th><th>Lag_day7_hour23</th><th>Consumption</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='int' title='int64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td></td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>2016-01-08</td><td>1</td><td>0</td><td>27614</td><td>26579</td><td>25719.2</td><td>25864.6</td><td>25918.6</td><td>27091.9</td><td>28533</td><td class=vellipsis>&hellip;</td><td>30166.1</td><td>29461.3</td><td>29242.8</td><td>28069.1</td><td>27112.4</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>2016-01-08</td><td>2</td><td>0</td><td>27614</td><td>26579</td><td>25719.2</td><td>25864.6</td><td>25918.6</td><td>27091.9</td><td>28533</td><td class=vellipsis>&hellip;</td><td>30166.1</td><td>29461.3</td><td>29242.8</td><td>28069.1</td><td>25975.3</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>2016-01-08</td><td>3</td><td>0</td><td>27614</td><td>26579</td><td>25719.2</td><td>25864.6</td><td>25918.6</td><td>27091.9</td><td>28533</td><td class=vellipsis>&hellip;</td><td>30166.1</td><td>29461.3</td><td>29242.8</td><td>28069.1</td><td>25315.5</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>2016-01-08</td><td>4</td><td>0</td><td>27614</td><td>26579</td><td>25719.2</td><td>25864.6</td><td>25918.6</td><td>27091.9</td><td>28533</td><td class=vellipsis>&hellip;</td><td>30166.1</td><td>29461.3</td><td>29242.8</td><td>28069.1</td><td>25128.2</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>2016-01-08</td><td>5</td><td>0</td><td>27614</td><td>26579</td><td>25719.2</td><td>25864.6</td><td>25918.6</td><td>27091.9</td><td>28533</td><td class=vellipsis>&hellip;</td><td>30166.1</td><td>29461.3</td><td>29242.8</td><td>28069.1</td><td>25356.2</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>2016-01-08</td><td>6</td><td>0</td><td>27614</td><td>26579</td><td>25719.2</td><td>25864.6</td><td>25918.6</td><td>27091.9</td><td>28533</td><td class=vellipsis>&hellip;</td><td>30166.1</td><td>29461.3</td><td>29242.8</td><td>28069.1</td><td>26338.7</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>2016-01-08</td><td>7</td><td>0</td><td>27614</td><td>26579</td><td>25719.2</td><td>25864.6</td><td>25918.6</td><td>27091.9</td><td>28533</td><td class=vellipsis>&hellip;</td><td>30166.1</td><td>29461.3</td><td>29242.8</td><td>28069.1</td><td>28086.4</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>2016-01-08</td><td>8</td><td>0</td><td>27614</td><td>26579</td><td>25719.2</td><td>25864.6</td><td>25918.6</td><td>27091.9</td><td>28533</td><td class=vellipsis>&hellip;</td><td>30166.1</td><td>29461.3</td><td>29242.8</td><td>28069.1</td><td>32702.2</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>2016-01-08</td><td>9</td><td>0</td><td>27614</td><td>26579</td><td>25719.2</td><td>25864.6</td><td>25918.6</td><td>27091.9</td><td>28533</td><td class=vellipsis>&hellip;</td><td>30166.1</td><td>29461.3</td><td>29242.8</td><td>28069.1</td><td>35788.2</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>2016-01-08</td><td>10</td><td>0</td><td>27614</td><td>26579</td><td>25719.2</td><td>25864.6</td><td>25918.6</td><td>27091.9</td><td>28533</td><td class=vellipsis>&hellip;</td><td>30166.1</td><td>29461.3</td><td>29242.8</td><td>28069.1</td><td>36843.2</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>10 rows &times; 51 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#1420a079e40 10x51>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electricity_long = transform_long(electricity)\n",
    "print(electricity_long.head())\n",
    "electricity = electricity[169:electricity.nrows,:]\n",
    "electricity_wide = transform_wide(electricity_long)\n",
    "electricity_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to accomplish the tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Task 1\n",
    "\n",
    "When we try to forecast the electricity consumption, we can use the consumption of values of 48 and 168 hours ago. To assign the value of these numbers would be our naïve approach. Our So, our MAPE values will be like these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.449188482612284\n",
      "8.060314509077504\n"
     ]
    }
   ],
   "source": [
    "predict_lag168 = electricity[:, [f.Test, shift(f.Consumption, n = 168)]][f.Test == 1, :]\n",
    "predict_lag48 = electricity[:, [f.Test, shift(f.Consumption, n = 48)]][f.Test == 1, :]\n",
    "\n",
    "MAPE_lag168 = calculate_mape(dt.Frame(pred = predict_lag168[\"Consumption\"], true = electricity[f.Test == 1, f.Consumption]))\n",
    "MAPE_lag48 = calculate_mape(dt.Frame(pred = predict_lag48[\"Consumption\"], true = electricity[f.Test == 1, f.Consumption]))\n",
    "\n",
    "print(MAPE_lag168)\n",
    "print(MAPE_lag48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAPE of lag 168 is 5.334224610142467 and MAPE of lag 48 is 8.630745447930549. Lag 168 naïve approach performs better than the lag 48 naïve approach. We can compare all other model with lag 168 naïve approach. With this approach, we see that weekly seasonality is more important than the two-day seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Task 2\n",
    "\n",
    "Rather than using the consumption of seven days ago, we can create a model that uses the lag 168 and lag 48 values as input. Our model can be a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.228194547043501\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "X_train = electricity_long[electricity[:, f.Test].to_pandas() == 0, [f.Lag_48, f.Lag_168]]\n",
    "y_train = electricity_long[electricity[:, f.Test].to_pandas() == 0, f.Consumption]\n",
    "X_test = electricity_long[electricity[:, f.Test].to_pandas() == 1, [f.Lag_48, f.Lag_168]]\n",
    "y_test = electricity_long[electricity[:, f.Test].to_pandas() == 1, f.Consumption]\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "predict_lr = lin_reg.predict(X_test)\n",
    "MAPE_lr = calculate_mape(dt.Frame(pred = predict_lr, true = y_test))\n",
    "print(MAPE_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compare the MAPE value of this model with lag 168 naïve approach, it is better to use the naïve approach than this linear regression. So, it means that out model is not good enough than just predicting the value of last week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Task 3\n",
    "\n",
    "In the linear regression model, we didn't divide the data respect to hours. So, our approach assumes that every hour will have the same coefficient. If this is not true, we need to model each hour separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>Hour</th><th>MAPE</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>0</td><td>3.26278</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>1</td><td>3.28309</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>2</td><td>3.42223</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>3</td><td>3.20699</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>4</td><td>3.18302</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>5</td><td>3.18745</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>6</td><td>3.14806</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>19</td><td>3.43379</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>20</td><td>3.16435</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>21</td><td>3.16626</td></tr>\n",
       "    <tr><td class='row_index'>10</td><td>22</td><td>3.16697</td></tr>\n",
       "    <tr><td class='row_index'>11</td><td>23</td><td>3.38674</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>12 rows &times; 2 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#1420c4a5150 12x2>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_hourly = dt.Frame()\n",
    "\n",
    "for i in range(0, 24):\n",
    "    X_train = electricity_long[(f.Hour == i) & (electricity[:, f.Test].to_pandas() == 0), [f.Lag_48, f.Lag_168]]\n",
    "    y_train = electricity_long[(f.Hour == i) & (electricity[:, f.Test].to_pandas() == 0), f.Consumption]\n",
    "    X_test = electricity_long[(f.Hour == i) & (electricity[:, f.Test].to_pandas() == 1), [f.Lag_48, f.Lag_168]]\n",
    "    y_test = electricity_long[(f.Hour == i) & (electricity[:, f.Test].to_pandas() == 1), f.Consumption]\n",
    "    \n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    predict_lr = lin_reg.predict(X_test)\n",
    "    MAPE_lr_hourly = calculate_mape(dt.Frame(pred = predict_lr, true = y_test))\n",
    "    model_lr_hourly.rbind(dt.Frame({\"Hour\" : [i], \"MAPE\" : [MAPE_lr_hourly]}))\n",
    "\n",
    "model_lr_hourly\n",
    "model_lr_hourly[f.MAPE <= MAPE_lag168,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we model all hours data individually, we see that there are 12 models that are better than the naïve approach. So, we still can say that naïve approach is a better approach, which means that weekly seasonality is more important than daily seasonality (or the importance of the weekly seaesonality is more than the importance of the hourly seasonality)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Task 4\n",
    "\n",
    "Now, we have some linear regression models for all hour. We can go further in this step. We can create more features for a model and use a penalized regression model for creating a more generalized model. We can use all seven day ago hourly consumption values to predict the next day's consumption for every hour. So we will create 24 models with these features. We can create a Lasso Regression as a penalized regression. With adding L1 norm of the coefficients in the objective function, we can prevent the model from overfitting. In Lasso Regression, alpha is an important hyper parameter. So, we can use 10-fold cross validation to choose the best alpha value and predict *Consumption* values with these hourly models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>Hour</th><th>MAPE</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='int' title='int32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='float' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>0</td><td>1.4203</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>1</td><td>1.57439</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>2</td><td>1.63322</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>3</td><td>1.50176</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>4</td><td>1.49766</td></tr>\n",
       "    <tr><td class='row_index'>5</td><td>5</td><td>1.43566</td></tr>\n",
       "    <tr><td class='row_index'>6</td><td>6</td><td>1.69015</td></tr>\n",
       "    <tr><td class='row_index'>7</td><td>7</td><td>1.87627</td></tr>\n",
       "    <tr><td class='row_index'>8</td><td>8</td><td>2.5772</td></tr>\n",
       "    <tr><td class='row_index'>9</td><td>16</td><td>3.00183</td></tr>\n",
       "    <tr><td class='row_index'>10</td><td>17</td><td>2.04782</td></tr>\n",
       "    <tr><td class='row_index'>11</td><td>18</td><td>1.57548</td></tr>\n",
       "    <tr><td class='row_index'>12</td><td>19</td><td>1.56931</td></tr>\n",
       "    <tr><td class='row_index'>13</td><td>20</td><td>1.63161</td></tr>\n",
       "    <tr><td class='row_index'>14</td><td>21</td><td>1.67025</td></tr>\n",
       "    <tr><td class='row_index'>15</td><td>22</td><td>1.50228</td></tr>\n",
       "    <tr><td class='row_index'>16</td><td>23</td><td>1.74977</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>17 rows &times; 2 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<Frame#1420a75cd20 17x2>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lasso_hourly = dt.Frame()\n",
    "\n",
    "for i in range(0, 24):\n",
    "    X_train = electricity_wide[(f.Hour == i) & (electricity[:, f.Test].to_pandas() == 0), \"Lag_day2_hour0\":\"Lag_day7_hour23\"]\n",
    "    y_train = electricity_wide[(f.Hour == i) & (electricity[:, f.Test].to_pandas() == 0), f.Consumption]\n",
    "    X_test = electricity_wide[(f.Hour == i) & (electricity[:, f.Test].to_pandas() == 1), \"Lag_day2_hour0\":\"Lag_day7_hour23\"]\n",
    "    y_test = electricity_wide[(f.Hour == i) & (electricity[:, f.Test].to_pandas() == 1), f.Consumption]\n",
    "    \n",
    "    las_reg = LassoCV(cv=10, random_state=12345, max_iter=100000).fit(X_train, y_train.to_numpy().ravel())\n",
    "    predict_lasso_hourly = las_reg.predict(X_test)\n",
    "    MAPE_lasso_hourly = calculate_mape(dt.Frame(pred = predict_lasso_hourly, true = y_test))\n",
    "    model_lasso_hourly.rbind(dt.Frame({\"Hour\" : [i], \"MAPE\" : [MAPE_lasso_hourly]}))\n",
    "\n",
    "\n",
    "model_lasso_hourly\n",
    "model_lasso_hourly[f.MAPE <= MAPE_lag168,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have better MAPE results than the naïve approach. So, we can conclude that using all hourly values of seven and two days ago in Lasso Regression is a better approach to forecast the next day's consumption than naïve approach. Also, we can understand the importance of using more features in a model. If additional variables do not contribute to score, they will have zero coefficients. So, there is nothing wrong with using more features in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Task 5\n",
    "\n",
    "For a better solution, we can try the fused regression, which also adds the differences of consecutive coefficients with a multiplier. We can make an implementation with the help of _cvxpy_ package. In this implementation, we are constructing models for every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = cp.Variable(48)\n",
    "model_fused_hourly = dt.Frame()\n",
    "\n",
    "for i in range(0, 24):\n",
    "    X_train = electricity_wide[(electricity[:, f.Test].to_pandas() == 0), \"Lag_day2_hour0\":\"Lag_day7_hour23\"]\n",
    "    y_train = electricity_wide[(electricity[:, f.Test].to_pandas() == 0), f.Consumption]\n",
    "    X_test = electricity_wide[(electricity[:, f.Test].to_pandas() == 1), \"Lag_day2_hour0\":\"Lag_day7_hour23\"]\n",
    "    y_test = electricity_wide[(electricity[:, f.Test].to_pandas() == 1), f.Consumption]\n",
    "    \n",
    "    obj = np.sum(np.square(y_train - np.dot(X_train, beta))) + 3.401877 * np.sum(np.square(beta)) + 3.401877 * np.abs(cp.atoms.pnorm(cp.atoms.affine.diff.diff(x = beta, k = 1), 1))\n",
    "    prob = cp.Problem(cp.Minimize(obj))\n",
    "    result = prob.solve()\n",
    "    \n",
    "    betas = beta.value\n",
    "    predict_fused_hour = np.dot(X_test, betas)\n",
    "    MAPE_fused_hour = calculate_mape(dt.Frame(pred = predict_fused_hour, true = y_test))\n",
    "    model_fused_hourly = model_fused_hourly.rbind(dt.Frame({Hour = [i], MAPE = [MAPE_fused_hour]}))\n",
    "\n",
    "model_fused_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we calculate MAPE values, we get the similar results with Lasso Regression. This approach could have better result, but we couldn't apply a grid search for lambda values. A further work could be to find a solution to come up with best lambda values. After this process we will not include the results of fused regression because of the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Task 6\n",
    "\n",
    "Now, at the end of the task, we can plot all MAPE values in a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "All_MAPE = [[MAPE_lag168], [MAPE_lag48], [MAPE_lr], model_lr_hourly[\"MAPE\"].to_list()[0],  model_lasso_hourly[\"MAPE\"].to_list()[0]]\n",
    "Labels = ['Lag_168', 'Lag_48', 'LR', 'Hourly_LR', 'Hourly_Lasso']\n",
    "_ = plt.boxplot(All_MAPE, labels = Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the results of all MAPE values, we see that hourly lasso models are far better than the others. As we explained before, it is the expected result thanks to using more features and regularization that tries to overcome the overfitting problem. At the end of the task, we can come up with some information like below:\n",
    "\n",
    "- In our data, weekly seasonality is more important than daily and hourly seasonality.\n",
    "- To use all hourly consumption of a day is a better approach to create a model. In this type of situations, we need to consider the penalized regression to reduce the chance of overfitting.\n",
    "- To use two-day and one-week before consumption information is a reliable process with respect to their MAPE values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES\n",
    "- [EPIAS](https://seffaflik.epias.com.tr/)\n",
    "- [MAPE](https://www.statology.org/mape-r/)\n",
    "- [DATATABLE](https://datatable.readthedocs.io/en/latest/)\n",
    "- [CVXPY](https://www.cvxpy.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
